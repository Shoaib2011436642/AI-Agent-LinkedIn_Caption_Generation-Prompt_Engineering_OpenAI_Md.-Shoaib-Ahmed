{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **AI Agent** For **LinkedIn Caption** Generation Using **Prompt Engineering** & **OpenAI** Model\n",
        "## Developed By: *Md. Shoaib Ahmed*"
      ],
      "metadata": {
        "id": "53kZOmxkntJO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Required Libraries"
      ],
      "metadata": {
        "id": "GK9hiZjqkkYf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttHsK1fHkalM",
        "outputId": "98def143-d128-46b2-b5ff-656e2da70444"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.106.1)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.33-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.24)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
            "  Downloading langchain_core-0.3.76-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Downloading langchain_openai-0.3.33-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.76-py3-none-any.whl (447 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: langchain-core, langchain-openai\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.75\n",
            "    Uninstalling langchain-core-0.3.75:\n",
            "      Successfully uninstalled langchain-core-0.3.75\n",
            "Successfully installed langchain-core-0.3.76 langchain-openai-0.3.33\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai python-dotenv langchain-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "7xh7KpzIknfJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_openai import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "VL_hRE-3ktN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Up OpenAI Credentials"
      ],
      "metadata": {
        "id": "FWEkOeW1mf77"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"ghp_Put_Your_Own_Github_Token\"\n",
        "os.environ[\"OPENAI_API_BASE\"] = \"https://models.github.ai/inference\"  # default base url\n",
        "MODEL_NAME = \"openai/gpt-4o-mini\""
      ],
      "metadata": {
        "id": "UxNMib-MmivG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Prompt Template"
      ],
      "metadata": {
        "id": "MLwUJ_8Dq2bY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = PromptTemplate(\n",
        "    input_variables=[\"topic\", \"language\"],\n",
        "    template=\"\"\"\n",
        "You are a professional LinkedIn content creator.\n",
        "Write a LinkedIn post about the topic: \"{topic}\".\n",
        "The post should be structured, engaging, and written in {language}.\n",
        "The style must be professional but conversational.\n",
        "Generate 2-4 paragraphs.\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "cbfQYn6XnG-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the LLMChain"
      ],
      "metadata": {
        "id": "QwDU_mWBq_BG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model_name=MODEL_NAME,\n",
        "    temperature=0.7,\n",
        "    max_tokens=700\n",
        ")\n",
        "\n",
        "linkedin_post_chain = LLMChain(\n",
        "    llm=llm,\n",
        "    prompt=prompt_template\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pjw5i2S0rB6K",
        "outputId": "bcec5d2e-4879-42eb-c1d3-803154a6aae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1169060247.py:9: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  linkedin_post_chain = LLMChain(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get User Input and Generate the Post"
      ],
      "metadata": {
        "id": "sdeXbAqIrHCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_linkedin_post(topic: str, language: str):\n",
        "    result = linkedin_post_chain.run(topic=topic, language=language)\n",
        "    return result\n",
        "\n",
        "# Example run\n",
        "topic_input = input(\"Enter the topic of the LinkedIn post: \")\n",
        "language_input = input(\"Enter the language (e.g., English, Bengali, Spanish): \")\n",
        "\n",
        "generated_post = generate_linkedin_post(topic_input, language_input)\n",
        "\n",
        "print(\"\\n Generated LinkedIn Post:\\n\")\n",
        "print(generated_post)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9jXO7ROrJyc",
        "outputId": "9e991653-5ce4-415d-cecb-ea7349d23bb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the topic of the LinkedIn post: Agentic AI\n",
            "Enter the language (e.g., English, Bengali, Spanish): English\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1864142939.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  result = linkedin_post_chain.run(topic=topic, language=language)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Generated LinkedIn Post:\n",
            "\n",
            "üåü **Unlocking the Future: The Rise of Agentic AI** üåü\n",
            "\n",
            "In our rapidly evolving digital landscape, the introduction of **Agentic AI** is reshaping how we interact with technology. Unlike traditional AI systems that merely respond to commands, Agentic AI possesses the ability to make independent decisions, learn from its environment, and adapt based on new information. This shift not only enhances efficiency but also opens up exciting possibilities for innovation across various industries. Imagine a world where AI can autonomously manage complex tasks, from optimizing supply chains to personalizing customer experiences‚Äîthis is not a distant future; it's happening now!\n",
            "\n",
            "However, with great power comes great responsibility. As we embrace this transformative technology, it‚Äôs crucial to address the ethical implications and ensure that we implement robust governance frameworks. How do we maintain accountability? What safeguards can we put in place to prevent bias and ensure that these intelligent agents align with our values? Engaging in these conversations today will help us harness the full potential of Agentic AI while fostering trust and transparency.\n",
            "\n",
            "As professionals, we have a unique opportunity to lead the charge in integrating Agentic AI into our organizations. By staying informed and proactive, we can drive meaningful change that benefits not just our businesses, but society as a whole. Let‚Äôs collaborate, share insights, and build a future where AI doesn‚Äôt just assist us but empowers us to achieve new heights. What are your thoughts on the potential of Agentic AI? Let‚Äôs discuss in the comments! üí¨‚ú® #AgenticAI #Innovation #FutureOfWork #AIethics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User Input Example 1"
      ],
      "metadata": {
        "id": "2GM5RoO_uka5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example run\n",
        "topic_input = input(\"Enter the topic of the LinkedIn post: \")\n",
        "language_input = input(\"Enter the language (e.g., English, Bengali, Spanish): \")\n",
        "\n",
        "generated_post = generate_linkedin_post(topic_input, language_input)\n",
        "\n",
        "print(\"\\n Generated LinkedIn Post:\\n\")\n",
        "print(generated_post)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oV7gEEEJuWDN",
        "outputId": "afa2fcb0-60f2-41fc-be8a-390c25b827dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the topic of the LinkedIn post: AI in Healthcare\n",
            "Enter the language (e.g., English, Bengali, Spanish): English\n",
            "\n",
            " Generated LinkedIn Post:\n",
            "\n",
            "üåü **The Future of Healthcare: Embracing AI Innovations** üåü\n",
            "\n",
            "In recent years, artificial intelligence (AI) has transcended the realm of tech and infiltrated one of the most vital sectors of our society: healthcare. From diagnostics to patient management, AI is reshaping how we approach health and wellness. Imagine algorithms that can analyze medical images with remarkable accuracy or chatbots that assist patients 24/7, answering their queries and guiding them to the right resources! The potential is not just exciting; it‚Äôs transformative. \n",
            "\n",
            "But while the technology is impressive, the real game-changer lies in how AI enhances human capabilities. For healthcare professionals, AI can serve as a powerful ally, providing data-driven insights that facilitate more informed decision-making. It allows doctors to spend less time sifting through information and more time focusing on what truly matters: patient care. The synergy of human expertise and AI efficiency could lead us to quicker diagnoses, personalized treatment plans, and ultimately, better patient outcomes.\n",
            "\n",
            "However, as we navigate this innovative landscape, it‚Äôs essential to consider the ethical implications and the importance of data privacy. Trust in technology is paramount, and maintaining patient confidentiality must remain a top priority. As we continue to explore the possibilities, collaboration among tech developers, healthcare providers, and regulatory bodies will be crucial in ensuring that AI serves as a force for good in our healthcare systems.\n",
            "\n",
            "Let‚Äôs embrace this exciting journey and work together to harness AI‚Äôs potential to revolutionize healthcare for the better. What are your thoughts on the integration of AI in the medical field? Share your insights below! üí°üëá #AIinHealthcare #InnovateForHealth #FutureOfMedicine\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## User Input Example 2"
      ],
      "metadata": {
        "id": "OfAOvm2guu4N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example run\n",
        "topic_input = input(\"Enter the topic of the LinkedIn post: \")\n",
        "language_input = input(\"Enter the language (e.g., English, Bengali, Spanish): \")\n",
        "\n",
        "generated_post = generate_linkedin_post(topic_input, language_input)\n",
        "\n",
        "print(\"\\n Generated LinkedIn Post:\\n\")\n",
        "print(generated_post)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EG5l3fC0uwmS",
        "outputId": "2173f536-5e42-42ee-eef9-b620d15d2a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the topic of the LinkedIn post: Remote Work Productivity\n",
            "Enter the language (e.g., English, Bengali, Spanish): Bengali\n",
            "\n",
            " Generated LinkedIn Post:\n",
            "\n",
            "üîó **‡¶∞‡¶ø‡¶Æ‡ßã‡¶ü ‡¶ï‡¶æ‡¶ú‡ßá‡¶∞ ‡¶â‡ßé‡¶™‡¶æ‡¶¶‡¶®‡¶∂‡ßÄ‡¶≤‡¶§‡¶æ: ‡¶®‡¶§‡ßÅ‡¶® ‡¶Ø‡ßÅ‡¶ó‡ßá‡¶∞ ‡¶®‡¶§‡ßÅ‡¶® ‡¶ö‡ßç‡¶Ø‡¶æ‡¶≤‡ßá‡¶û‡ßç‡¶ú** üîó\n",
            "\n",
            "‡¶¨‡¶∞‡ßç‡¶§‡¶Æ‡¶æ‡¶® ‡¶Ø‡ßÅ‡¶ó‡ßá ‡¶∞‡¶ø‡¶Æ‡ßã‡¶ü ‡¶ï‡¶æ‡¶ú ‡¶Ü‡¶Æ‡¶æ‡¶¶‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø ‡¶è‡¶ï‡¶ü‡¶ø ‡¶®‡¶§‡ßÅ‡¶® ‡¶¨‡¶æ‡¶∏‡ßç‡¶§‡¶¨‡¶§‡¶æ‡•§ ‡¶è‡¶ï‡¶¶‡¶ø‡¶ï‡ßá ‡¶ï‡¶∞‡ßç‡¶Æ‡¶ú‡ßÄ‡¶¨‡¶®‡ßá‡¶∞ ‡¶®‡¶Æ‡¶®‡ßÄ‡¶Ø‡¶º‡¶§‡¶æ ‡¶è‡¶¨‡¶Ç ‡¶Ö‡¶®‡ßç‡¶Ø‡¶¶‡¶ø‡¶ï‡ßá ‡¶ï‡¶æ‡¶ú‡ßá‡¶∞ ‡¶ö‡¶æ‡¶™, ‡¶è‡¶á ‡¶¶‡ßÅ‡¶á‡ßü‡ßá‡¶∞ ‡¶Æ‡¶ß‡ßç‡¶Ø‡ßá ‡¶≠‡¶æ‡¶∞‡¶∏‡¶æ‡¶Æ‡ßç‡¶Ø ‡¶∞‡¶æ‡¶ñ‡¶æ ‡¶Ö‡¶®‡ßá‡¶ï‡ßá‡¶∞ ‡¶ú‡¶®‡ßç‡¶Ø‡¶á ‡¶ö‡ßç‡¶Ø‡¶æ‡¶≤‡ßá‡¶û‡ßç‡¶ú ‡¶π‡ßü‡ßá ‡¶¶‡¶æ‡¶Å‡ßú‡¶ø‡ßü‡ßá‡¶õ‡ßá‡•§ ‡¶ï‡¶ø‡¶®‡ßç‡¶§‡ßÅ ‡¶∏‡¶†‡¶ø‡¶ï ‡¶ï‡ßå‡¶∂‡¶≤ ‡¶è‡¶¨‡¶Ç ‡¶Æ‡¶®‡ßã‡¶≠‡¶æ‡¶¨‡ßá‡¶∞ ‡¶Æ‡¶æ‡¶ß‡ßç‡¶Ø‡¶Æ‡ßá ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶Ü‡¶Æ‡¶æ‡¶¶‡ßá‡¶∞ ‡¶â‡ßé‡¶™‡¶æ‡¶¶‡¶®‡¶∂‡ßÄ‡¶≤‡¶§‡¶æ ‡¶¨‡¶æ‡¶°‡¶º‡¶æ‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶ø‡•§ \n",
            "\n",
            "‡¶™‡ßç‡¶∞‡¶•‡¶Æ‡¶§, ‡¶è‡¶ï‡¶ü‡¶ø ‡¶∏‡ßÅ‡¶∏‡¶Ç‡¶ó‡¶†‡¶ø‡¶§ ‡¶ï‡¶æ‡¶ú‡ßá‡¶∞ ‡¶™‡¶∞‡¶ø‡¶¨‡ßá‡¶∂ ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶æ ‡¶Ö‡¶§‡ßç‡¶Ø‡¶®‡ßç‡¶§ ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨‡¶™‡ßÇ‡¶∞‡ßç‡¶£‡•§ ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶°‡ßá‡¶∏‡ßç‡¶ï‡¶ü‡¶ø ‡¶™‡¶∞‡¶ø‡¶∑‡ßç‡¶ï‡¶æ‡¶∞ ‡¶è‡¶¨‡¶Ç ‡¶∏‡ßÅ‡¶∂‡ßÉ‡¶ô‡ßç‡¶ñ‡¶≤ ‡¶∞‡¶æ‡¶ñ‡ßÅ‡¶®, ‡¶ï‡¶æ‡¶∞‡¶£ ‡¶è‡¶ü‡¶ø ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶Æ‡¶®‡ßã‡¶Ø‡ßã‡¶ó ‡¶ï‡ßá‡¶®‡ßç‡¶¶‡ßç‡¶∞‡ßÄ‡¶≠‡ßÇ‡¶§ ‡¶ï‡¶∞‡¶§‡ßá ‡¶∏‡¶π‡¶æ‡¶Ø‡¶º‡¶§‡¶æ ‡¶ï‡¶∞‡¶¨‡ßá‡•§ ‡¶¶‡ßç‡¶¨‡¶ø‡¶§‡ßÄ‡ßü‡¶§, ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶¨‡ßç‡¶Ø‡¶¨‡¶∏‡ßç‡¶•‡¶æ‡¶™‡¶®‡¶æ ‡¶è‡¶ï‡¶ü‡¶ø ‡¶Æ‡ßÇ‡¶≤ ‡¶¶‡¶ø‡¶ï‡•§ ‡¶ï‡¶æ‡¶ú‡ßá‡¶∞ ‡¶∏‡¶Æ‡¶Ø‡¶º ‡¶∏‡ßÄ‡¶Æ‡¶æ‡¶¨‡¶¶‡ßç‡¶ß ‡¶ï‡¶∞‡ßá ‡¶¶‡¶ø‡¶® ‡¶è‡¶¨‡¶Ç ‡¶¨‡¶ø‡¶∞‡¶§‡¶ø ‡¶®‡¶ø‡¶®‡•§ ‡¶õ‡ßã‡¶ü ‡¶õ‡ßã‡¶ü ‡¶¨‡¶ø‡¶∞‡¶§‡¶ø ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶Æ‡¶∏‡ßç‡¶§‡¶ø‡¶∑‡ßç‡¶ï‡¶ï‡ßá ‡¶∞‡¶ø‡¶´‡ßç‡¶∞‡ßá‡¶∂ ‡¶ï‡¶∞‡¶§‡ßá ‡¶∏‡¶æ‡¶π‡¶æ‡¶Ø‡ßç‡¶Ø ‡¶ï‡¶∞‡ßá ‡¶è‡¶¨‡¶Ç ‡¶¶‡ßÄ‡¶∞‡ßç‡¶ò‡¶Æ‡ßá‡¶Ø‡¶º‡¶æ‡¶¶‡ßá ‡¶â‡ßé‡¶™‡¶æ‡¶¶‡¶®‡¶∂‡ßÄ‡¶≤‡¶§‡¶æ ‡¶¨‡¶æ‡¶°‡¶º‡¶æ‡¶Ø‡¶º‡•§\n",
            "\n",
            "‡¶Ö‡¶¨‡¶∂‡ßá‡¶∑‡ßá, ‡¶Ø‡ßã‡¶ó‡¶æ‡¶Ø‡ßã‡¶ó‡ßá‡¶∞ ‡¶ó‡ßÅ‡¶∞‡ßÅ‡¶§‡ßç‡¶¨ ‡¶ï‡¶ñ‡¶®‡ßã‡¶á ‡¶Ö‡¶∏‡ßç‡¶¨‡ßÄ‡¶ï‡¶æ‡¶∞ ‡¶ï‡¶∞‡¶æ ‡¶Ø‡¶æ‡¶¨‡ßá ‡¶®‡¶æ‡•§ ‡¶∏‡¶π‡¶ï‡¶∞‡ßç‡¶Æ‡ßÄ‡¶¶‡ßá‡¶∞ ‡¶∏‡¶æ‡¶•‡ßá ‡¶®‡¶ø‡¶Ø‡¶º‡¶Æ‡¶ø‡¶§ ‡¶Ø‡ßã‡¶ó‡¶æ‡¶Ø‡ßã‡¶ó ‡¶∞‡¶æ‡¶ñ‡ßÅ‡¶® ‡¶è‡¶¨‡¶Ç ‡¶ü‡¶ø‡¶Æ ‡¶Æ‡¶ø‡¶ü‡¶ø‡¶Ç‡¶Ø‡¶º‡ßá ‡¶Ö‡¶Ç‡¶∂‡¶ó‡ßç‡¶∞‡¶π‡¶£ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§ ‡¶è‡¶ü‡¶ø ‡¶Ü‡¶™‡¶®‡¶æ‡¶ï‡ßá ‡¶¶‡¶≤‡ßá‡¶∞ ‡¶∏‡¶ô‡ßç‡¶ó‡ßá ‡¶∏‡¶Ç‡¶Ø‡ßÅ‡¶ï‡ßç‡¶§ ‡¶ï‡¶∞‡ßá ‡¶∞‡¶æ‡¶ñ‡¶¨‡ßá ‡¶è‡¶¨‡¶Ç ‡¶è‡¶ï‡¶∏‡¶æ‡¶•‡ßá ‡¶ï‡¶æ‡¶ú ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶Ü‡¶¨‡¶π ‡¶§‡ßà‡¶∞‡¶ø ‡¶ï‡¶∞‡¶¨‡ßá‡•§ \n",
            "\n",
            "‡¶Ü‡¶Æ‡¶æ‡¶¶‡ßá‡¶∞ ‡¶è‡¶á ‡¶®‡¶§‡ßÅ‡¶® ‡¶ï‡¶æ‡¶ú‡ßá‡¶∞ ‡¶™‡¶∞‡¶ø‡¶¨‡ßá‡¶∂‡ßá ‡¶â‡ßé‡¶™‡¶æ‡¶¶‡¶®‡¶∂‡ßÄ‡¶≤‡¶§‡¶æ ‡¶¨‡¶ú‡¶æ‡¶Ø‡¶º ‡¶∞‡¶æ‡¶ñ‡¶æ ‡¶∏‡¶Æ‡ßç‡¶≠‡¶¨, ‡¶Ø‡¶¶‡¶ø ‡¶Ü‡¶Æ‡¶∞‡¶æ ‡¶ï‡¶ø‡¶õ‡ßÅ ‡¶∏‡¶π‡¶ú ‡¶ï‡ßå‡¶∂‡¶≤ ‡¶Ö‡¶®‡ßÅ‡¶∏‡¶∞‡¶£ ‡¶ï‡¶∞‡¶ø‡•§ ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶∞‡¶ø‡¶Æ‡ßã‡¶ü ‡¶ï‡¶æ‡¶ú‡ßá‡¶∞ ‡¶Ö‡¶≠‡¶ø‡¶ú‡ßç‡¶û‡¶§‡¶æ ‡¶ï‡ßá‡¶Æ‡¶®? ‡¶®‡¶ø‡¶ö‡ßá ‡¶Æ‡¶®‡ßç‡¶§‡¶¨‡ßç‡¶Ø ‡¶ï‡¶∞‡ßÅ‡¶®! üí¨\n"
          ]
        }
      ]
    }
  ]
}